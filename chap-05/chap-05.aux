\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{05-this_notes}
\citation{05-this_slides}
\citation{05-tj-qk}
\@writefile{toc}{\contentsline {chapter}{\numberline {第二章\hspace  {.3em}}语言模型和RNN \\ Language Models}{11}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}语言模型 \\ Language Models}{11}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}介绍 \\ Introduction}{11}{subsection.2.1.1}\protected@file@percent }
\newlabel{gram-raw}{{2.1.1}{11}{介绍 \\ Introduction}{subsection.2.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{N元语法 \\ N-Gram Language Models}{12}{subsubsection*.7}\protected@file@percent }
\newlabel{n-window}{{2.1}{12}{N元语法 \\ N-Gram Language Models}{equation.2.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}基于N元语法计算条件共现频率 \\ Calculation Prediction Probability in N-Gram Based Language Models}{12}{subsection.2.1.2}\protected@file@percent }
\newlabel{n-gram}{{2.1.2}{12}{基于N元语法计算条件共现频率 \\ Calculation Prediction Probability in N-Gram Based Language Models}{subsection.2.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{基于N元语法计算条件共现频率}{12}{subsubsection*.8}\protected@file@percent }
\citation{05-tj-qk}
\newlabel{bi-gram}{{2.2}{13}{基于N元语法计算条件共现频率}{equation.2.1.2}{}}
\newlabel{tri-gram}{{2.3}{13}{基于N元语法计算条件共现频率}{equation.2.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{预设参数n对n元语法模型的影响}{13}{subsubsection*.9}\protected@file@percent }
\citation{05-stat-fail}
\citation{05-bengio03}
\citation{05-w2v}
\citation{05-w2v-model}
\citation{05-w2v-opti}
\citation{05-tj}
\@writefile{toc}{\contentsline {subsubsection}{N元语法模型的评价}{14}{subsubsection*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}基于窗口的语言模型 \\ Window-based Neural Language Model}{14}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}循环神经网络（RNN）的应用 \\ Application of RNN}{14}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces RNN单元的输入输出结构}}{15}{figure.2.1}\protected@file@percent }
\newlabel{05-RNN}{{2.1}{15}{RNN单元的输入输出结构}{figure.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces RNN可以用于文本生成。}}{15}{figure.2.2}\protected@file@percent }
\newlabel{05-prediction}{{2.2}{15}{RNN可以用于文本生成。}{figure.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}RNN语言模型的特点 \\ Advantages, Disadvantages and Applications of RNNs}{16}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}梯度爆炸和梯度消失的对策 \\ Solution to the Exploding and Vanishing Gradients}{16}{subsection.2.2.2}\protected@file@percent }
\newlabel{05-solution-vanish}{{2.2.2}{16}{梯度爆炸和梯度消失的对策 \\ Solution to the Exploding and Vanishing Gradients}{subsection.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces 梯度修剪缓解梯度爆炸问题的一个实证。}}{17}{figure.2.3}\protected@file@percent }
\newlabel{05-wall}{{2.3}{17}{梯度修剪缓解梯度爆炸问题的一个实证。}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}基于RNN的机器翻译 \\ Application: RNN Translation Model}{17}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces 最简单的基于RNN的机器翻译模型}}{18}{figure.2.4}\protected@file@percent }
\newlabel{05-rnn-nmt}{{2.4}{18}{最简单的基于RNN的机器翻译模型}{figure.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}章节附录}{18}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}维数灾难 \\ Curse of Dimensionality}{18}{subsection.2.3.1}\protected@file@percent }
\newlabel{curse}{{2.3.1}{18}{维数灾难 \\ Curse of Dimensionality}{subsection.2.3.1}{}}
\bibcite{05-this_notes}{notes05}
\bibcite{05-this_slides}{lecture06}
\bibcite{05-stat-fail}{On Chomsky and the Two Cultures of Statistical Learning}
\bibcite{05-bengio03}{A Neural Probabilistic Language Model}
\bibcite{05-w2v}{Word2Vec in gensim}
\bibcite{05-w2v-model}{Word2Vec CBOW and Skip-Gram}
\bibcite{05-w2v-opti}{Word2Vec Optimization}
\bibcite{05-tj}{统计自然语言处理}
\bibcite{05-tj-qk}{统计自然语言处理}
\bibcite{05-js}{计算语言学导论}
\@setckpt{chap-05/chap-05}{
\setcounter{page}{20}
\setcounter{equation}{3}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{3}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{1}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{0}
\setcounter{Item}{2}
\setcounter{Hfootnote}{7}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{19}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
}
